# BLENDED_LEARNING
# Implementation of Logistic Regression Model for Classifying Food Choices for Diabetic Patients

## AIM:
To implement a logistic regression model to classify food items for diabetic patients based on nutrition information.

## Equipments Required:
1. Hardware – PCs
2. Anaconda – Python 3.7 Installation / Jupyter notebook

## Algorithm
1. **Data Collection and Preprocessing**
   Load the food nutrition dataset, handle missing values, encode categorical labels, and normalize the nutritional features using scaling techniques.

2. **Data Splitting**
   Split the dataset into training and testing sets using an appropriate ratio (e.g., 80% training and 20% testing).

3. **Model Training**
   Train a Logistic Regression model using the training dataset to learn the relationship between nutritional features and diabetic suitability.

4. **Model Evaluation and Prediction**
   Test the model on the testing dataset and evaluate performance using accuracy, precision, recall, F1-score, and confusion matrix. Use the trained model to classify food items as suitable or unsuitable for diabetic patients.


## Program:
```
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

#Load the dataset
df=pd.read_csv('food_items (1).csv')
#inspect the dataset
print('Name:THENAMUDHEN S')
print('Reg. No: 2122225040471')
print("Dataset Overview:")
print(df.head())
print("\nDataset Info:")
print(df.info())
X_raw = df.iloc[:,:-1]
y_raw = df.iloc[:,-1:]
scaler= MinMaxScaler()
#Scaling the raw input features
X= scaler.fit_transform(X_raw)
#Create a LabelEncoder object
label_encoder = LabelEncoder()
#Encode the target variable
y= label_encoder.fit_transform(y_raw.values.ravel())
#Note the ravel() function flattens the vector


#First, let's split the the training and testing dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify =y, random_state=123)

#L2 penalty to shrink coefficients without removing any features from the model
penalty='l2'

#Our classification problem is multinomial
multi_class='multinomial'

#Use of lbfgs for L2 penalty and multinomial classes
solver= 'lbfgs'

#Max iteration=1000
max_iter=1000

#Define a logistic regression model with the  above arguments
l2_model = LogisticRegression(
    random_state=123,
    penalty=penalty,
    multi_class=multi_class, 
    solver=solver, 
    max_iter=max_iter
)
l2_model.fit(X_train, y_train)

y_pred= l2_model.predict(X_test)
print('Name:THENAMUDHEN S')
print('Reg. No: 212225040471')
print("\nModel Evaluation:")
print("Accuracy:",accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

#Confusion Matrix
conf_matrix= confusion_matrix(y_test, y_pred)
print(conf_matrix)

print('Name:THENAMUDHEN S')
print('Reg. No: 212225040471')


```

## Output:
<img width="994" height="718" alt="Screenshot 2026-02-26 081822" src="https://github.com/user-attachments/assets/a8f061d1-1554-44a4-8b96-f1f6c2971246" />
<img width="857" height="695" alt="Screenshot 2026-02-26 081843" src="https://github.com/user-attachments/assets/cb131100-0d79-4907-9568-704e513546eb" />
<img width="655" height="463" alt="Screenshot 2026-02-26 081853" src="https://github.com/user-attachments/assets/4df8f3bf-62c7-44ec-841b-b802257e196a" />

## Result:
Thus, the logistic regression model was successfully implemented to classify food items for diabetic patients based on nutritional information, and the model's performance was evaluated using various performance metrics such as accuracy, precision, and recall.
